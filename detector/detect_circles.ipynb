{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from pyzbar import pyzbar\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from PyPDF2 import PdfFileReader, PdfFileWriter\n",
    "from wand.image import Image\n",
    "from wand.color import Color\n",
    "import io\n",
    "import warnings\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = 20, 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pdf(filename, resolution=300):\n",
    "    with open(filename, 'rb') as f:\n",
    "        pdf_file = PdfFileReader(f)            \n",
    "        for i, page in enumerate(pdf_file.pages):\n",
    "            pdf_bytes = io.BytesIO()\n",
    "            writer = PdfFileWriter()\n",
    "            writer.addPage(page)\n",
    "            writer.write(pdf_bytes)\n",
    "            pdf_bytes.seek(0)\n",
    "            with Image(file=pdf_bytes, resolution=resolution) as img:\n",
    "                img.background_color = Color('white')\n",
    "                img.format = 'bmp'\n",
    "                img.alpha_channel = 'remove'\n",
    "                img_buffer = np.asarray(bytearray(img.make_blob()), dtype=np.uint8)\n",
    "                if img_buffer is not None:\n",
    "                    yield cv.imdecode(img_buffer, cv.IMREAD_UNCHANGED)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_omr_roi(image, highlight=True):\n",
    "    # assumes the image has the right orientation    \n",
    "    _retval, binary = cv.threshold(image, 128, 255, cv.THRESH_BINARY)\n",
    "    barcodes = pyzbar.decode(binary)\n",
    "    assert len(barcodes) == 2, \"Each page should have exactly two barcodes, found {}\".format(len(barcodes))\n",
    "    if highlight:\n",
    "        for barcode in barcodes:\n",
    "            # extract the bounding box location of the qrcode and draw a green \n",
    "            # frame around them\n",
    "            (x, y, w, h) = barcode.rect\n",
    "            cv.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "    # crop the image just to the barcodes\n",
    "    tl = np.array(barcodes[0].rect[:2])\n",
    "    br = np.array(barcodes[1].rect[:2]) + np.array(barcodes[1].rect[2:])\n",
    "    image = image[tl[1]:br[1], tl[0]:br[0]]\n",
    "    # get bounding box of the omr area from the bottom-right qrcode\n",
    "    br_match = re.search(r'\\((?P<tl_x>\\d+),(?P<tl_y>\\d+)\\)-\\((?P<br_x>\\d+),(?P<br_y>\\d+)\\)/(?P<diag>\\d+),(?P<page>\\d+)(?:,(?P<qrange_start>\\d+)-(?P<qrange_end>\\d+))?', str(barcodes[1].data))\n",
    "    if not br_match:\n",
    "        raise RuntimeError(\"Bottom-right qrcode encoded information do not comply with the expected format:\\nfound {}\".format(barcodes[1].data))\n",
    "    tl, br = np.array([br_match.group('tl_x'), br_match.group('tl_y')], dtype=float), np.array([br_match.group('br_x'), br_match.group('br_y')], dtype=float)\n",
    "    tl = (tl * image.shape[1] / 100.0 + 0.5).astype(int)\n",
    "    br = (br * image.shape[1] / 100.0 + 0.5).astype(int)\n",
    "    roi = image[tl[1]:br[1], tl[0]:br[0]]  \n",
    "    if highlight:\n",
    "        # draw a frame around the omr area\n",
    "        cv.rectangle(image, tuple(tl - 5), tuple(br + 5), (0, 0, 255), 3)\n",
    "    # determine the range of the questions in current pages\n",
    "    if br_match.group('qrange_start') is not None and br_match.group('qrange_end') is not None:        \n",
    "        qrange = (int(br_match.group('qrange_start')), int(br_match.group('qrange_end')))\n",
    "        # dispatch the list of answers\n",
    "        # FIXME: it should be encrypted\n",
    "        tl_match = re.search(r'\\[(?P<correct_sequence>[^\\]]+)\\]', str(barcodes[0].data))\n",
    "        if not tl_match:\n",
    "            raise RuntimeError(\"Top-left qrcode encoded information do not comply with the expected format:\\nfound {}\".format(barcodes[0].data))\n",
    "        correct_seq = tl_match.group('correct_sequence').split(',')[qrange[0] - 1:qrange[1]]\n",
    "        # the data returned are:\n",
    "        # - the image\n",
    "        # - the omr roi\n",
    "        # - the subsequence of correct answers for the questions appearing in the current page\n",
    "        # - the list of the questions appearing in the current page\n",
    "        return image, roi, correct_seq, list(range(qrange[0], qrange[1] + 1))\n",
    "    else:\n",
    "        warnings.warn('No answer on page {}'.format(br_match.group('page')))\n",
    "        return image, roi, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "### edge detection solution (currently 300dpi are required, to be checked)\n",
    "def process_page(page, highlight=True):\n",
    "    def circle_filled_area(image, c):\n",
    "        area = 0\n",
    "        center = np.array([c[0], c[1]])\n",
    "        radius = c[2]\n",
    "        xbounds = range(max(0, c[0] - c[2]), min(image.shape[1], c[0] + c[2] + 1))\n",
    "        ybounds = range(max(0, c[1] - c[2]), min(image.shape[0], c[1] + c[2] + 1))\n",
    "        for y in ybounds:\n",
    "            for x in xbounds:\n",
    "                point = np.array([x, y])\n",
    "                if cv.norm(point - center) <= radius and image[y, x] > 0:\n",
    "                    area += 1\n",
    "        return area\n",
    "    # get the prepared data, including the omr_roi\n",
    "    image, omr_roi, correct_sequence, qrange = prepare_omr_roi(page)\n",
    "    if correct_sequence is None and qrange is None: # there is no answer on current page\n",
    "        return []\n",
    "    # in order to detect the contours in the omr_roi, a blur and an adaptive thresholding is used\n",
    "    gray = cv.cvtColor(omr_roi, cv.COLOR_BGR2GRAY)\n",
    "    gray = cv.GaussianBlur(gray, (5, 5), 2, 2)\n",
    "    binary = cv.adaptiveThreshold(gray, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY_INV, 11, 2)\n",
    "    # get the contours\n",
    "    contours, _ = cv.findContours(binary, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_NONE)\n",
    "    # try to construct the circles\n",
    "    circles = []\n",
    "    # for each detcted contour\n",
    "    for contour in contours:\n",
    "        perimeter = cv.arcLength(contour, True)\n",
    "        # try to simplify it\n",
    "        approx = cv.approxPolyDP(contour, 0.01 * perimeter, True)\n",
    "        # and check whether it is a candidate to be a circle (in that case append it)\n",
    "        if len(approx) >= 8:                        \n",
    "            (cx, cy), radius = cv.minEnclosingCircle(contour)\n",
    "            circles.append((int(cx), int(cy), int(radius)))\n",
    "    # sort circles according to the x component (leftmost first, topmost after)\n",
    "    circles = sorted(circles)\n",
    "    # identify the reference_circles first, assuming the leftmost/topmost is the reference one\n",
    "    pivot = circles[0]\n",
    "    # the reference circles are those whose center is almost in the same column as the pivot\n",
    "    reference_circles = [c for c in circles if abs(c[0] - pivot[0]) <= pivot[2]]\n",
    "    # all the other are the answer circles\n",
    "    other_circles = [c for c in circles if abs(c[0] - pivot[0]) > pivot[2]]\n",
    "    # highlight the reference circles if required\n",
    "    if highlight:\n",
    "        for c in reference_circles:\n",
    "            cv.circle(omr_roi, c[:2], c[2], (255, 0, 255), 3)\n",
    "    # compute the mean area of the referene circles (helping to identify the filled ones later)\n",
    "    mean_area = np.mean(np.fromiter((c[2] * c[2] * np.pi for c in reference_circles), np.float))\n",
    "    # maintain the information as a mapping between the reference circle and all the\n",
    "    # answer circles on the same row\n",
    "    answer_circles = defaultdict(lambda: [])\n",
    "    # process the answer circles\n",
    "    for c in other_circles:\n",
    "        # find the closest reference circle, w.r.t. y coordinate\n",
    "        ydist = np.fromiter((abs(c[1] - rc[1]) for rc in reference_circles), int)\n",
    "        reference_circle = reference_circles[np.argmin(ydist)]\n",
    "        # compute the filled area within the circle\n",
    "        filled_area = circle_filled_area(binary, c)\n",
    "        # if the circle is at least half-full, then append it to the reference one and\n",
    "        # mark it as an answer (the boolean at lat)\n",
    "        if filled_area / mean_area > 0.5: # before was 0.4\n",
    "            answer_circles[reference_circle].append(c + (True,))\n",
    "        else:\n",
    "            answer_circles[reference_circle].append(c + (False,))\n",
    "    # now consider each reference circle from the topmost one down\n",
    "    answer_circles = sorted(answer_circles.items(), key=lambda item: item[0][1])\n",
    "    # check whether questions and the expected sequence of answers match\n",
    "    if len(answer_circles) > len(correct_sequence):\n",
    "        raise RuntimeError(\"Not enough answers {}\".format(correct_sequence))\n",
    "    # go through the questions (reference circles) and check the answers\n",
    "    correction = []\n",
    "    for i, ac in enumerate(answer_circles):\n",
    "        correct_res = set(correct_sequence[i])\n",
    "        all_res = set()\n",
    "        answers_res = set()    \n",
    "        for j, c in enumerate(ac[1]):\n",
    "            r = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"[j]\n",
    "            all_res.add(r)\n",
    "            if c[3]:\n",
    "                answers_res.add(r)\n",
    "                if r in correct_res and highlight:\n",
    "                    cv.circle(omr_roi, c[:2], c[2], (0, 255, 0), 5)\n",
    "                elif highlight:\n",
    "                    cv.circle(omr_roi, c[:2], c[2], (255, 0, 0), 5)\n",
    "            else:\n",
    "                if r in correct_res and highlight:\n",
    "                    cv.circle(omr_roi, c[:2], c[2], (255, 0, 0), 5)\n",
    "        # check if there are missing answers on the paper-sheet\n",
    "        missing_answers = correct_res - all_res\n",
    "        if len(missing_answers) > 0:\n",
    "            warnings.warn(\"For question {}, the correct answer{} {} {} not printed on the sheet\".format(qrange[i], \"s\" if len(missing_answers) > 1 else \"\", missing_answers, \"were\" if len(missing_answers) > 1 else \"was\"))\n",
    "            ytop = int(ac[0][1] - 1.3 * ac[0][2])\n",
    "            ybottom = int(ac[0][1] + 1.3 * ac[0][2])\n",
    "            cv.rectangle(omr_roi, (0, ytop), (omr_roi.shape[1], ybottom), (255, 0, 0), 7)\n",
    "            p = np.array(ac[0][0:2]) + [-ac[0][2], -ac[0][2] - 40]\n",
    "            cv.putText(omr_roi, \"Missing answer(s) {}\".format(missing_answers), tuple(p), cv.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 3)\n",
    "        if highlight:\n",
    "            # write a text with the given answers and the correct ones close to each reference circle\n",
    "            p = np.array(ac[0][0:2]) + [-ac[0][2], ac[0][2] + 40]\n",
    "            tmp = \"\".join(a for a in answers_res) if answers_res else \"None\"\n",
    "            tmp += \"/\" + \"\".join(a for a in correct_res)\n",
    "            cv.putText(omr_roi, tmp, tuple(p), cv.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 255), 3)\n",
    "        correction.append((answers_res, correct_res))\n",
    "    return correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Bottom-right qrcode encoded information do not comply with the expected format:\nfound b'(74,16)-(97,133)/336,1,1-3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-121-ae73f6ec0947>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"prova.pdf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpdf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mcorrection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_page\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m#plt.imshow(page)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-120-5f1a5d35df53>\u001b[0m in \u001b[0;36mprocess_page\u001b[0;34m(page, highlight)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0marea\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# get the prepared data, including the omr_roi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0momr_roi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqrange\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_omr_roi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcorrect_sequence\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mqrange\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# there is no answer on current page\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-119-dd7899c22c41>\u001b[0m in \u001b[0;36mprepare_omr_roi\u001b[0;34m(image, highlight)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mbr_match\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\((?P<tl_x>\\d+),(?P<tl_y>\\d+)\\)-\\((?P<br_x>\\d+),(?P<br_y>\\d+)\\)/(?P<diag>\\d+),(?P<page>\\d+)(?:,(?P<qrange_start>\\d+)-(?P<qrange_end>\\d+))?'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbarcodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbr_match\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Bottom-right qrcode encoded information do not comply with the expected format:\\nfound {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbarcodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mtl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbr_match\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tl_x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbr_match\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tl_y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbr_match\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'br_x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbr_match\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'br_y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mtl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtl\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m100.0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Bottom-right qrcode encoded information do not comply with the expected format:\nfound b'(74,16)-(97,133)/336,1,1-3'"
     ]
    }
   ],
   "source": [
    "pdf = read_pdf(\"prova.pdf\")\n",
    "for page in pdf:\n",
    "    correction = process_page(page)\n",
    "    #plt.imshow(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_answer_correctness(correction, **kwargs):\n",
    "    marking = []\n",
    "    for question in correction:\n",
    "        correct_rate = len(question[0] & question[1]) / len(question[1])\n",
    "        wrong_rate = len(question[0] - question[1]) / len(question[1])\n",
    "        marking.append((2.0 * correct_rate - wrong_rate) / 2.0)\n",
    "    return marking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_answer_correctness(correction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
